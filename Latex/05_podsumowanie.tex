\chapter{Podsumowanie}
W niniejszej pracy cel został osiągnięty - przebadane zostały dwa modele klasyfikacji: \textit{Bag-Of-Words} i \textit{fastText} oraz różne klasyfikatory, tak jak zakładał temat pracy. Pomyślnie udało się zaimplementować system automatycznego przypisywania tekstów w języku polskim do grup tematycznych z wykorzystaniem języka Python oraz interfejsów dostępnych w bibliotece \textit{SciKitLearn} i \textit{fastText}. Największym wyzwaniem w pracy okazało się poprawne dobranie tekstów artykułów tak, aby maksymalnie zwiększyć gamę klasyfikowanych kategorii. Zebranie korpusu wysokiej jakości składającego się z artykułów, było zadaniem nietrywialnym lecz możliwym do zrealizowania. Największą przeszkodą podczas zbierania danych były niepoprawnie dobierane tagi przez autorów tekstów, co skutkowało tym, że wiele kategorii było unikalnych względem całego korpusu. W efekcie, bardzo duża liczba artykułów musiała zostać odrzucona ze względu na brak szans na pomyślną klasyfikację, spowodowany niewystarczającą ilością danych do nauki. Praca jednoznacznie określa wady i zalety obu zastosowanych modeli i jednocześnie wskazuje, jakie usprawnienia powinny zostać rozważone w celu minimalizacji negatywnych efektów wybranych metod. System może z powodzeniem zostać zaimplementowany w większych systemach informatycznych w celu klasyfikacji tekstów na wybranych kategoriach. 

Podczas testów wykazano, że najskuteczniejszą metodą klasyfikacji była metoda \textit{Bag-Of-Words} wraz z klasyfikatorem \textit{SVM}. Był to jednocześnie  najszybciej uczący się klasyfikator. Kosztem tej dokładności w stosunku do metody \textit{fastText} okazał się czas potrzebny na klasyfikację.

W pracy zaproponowano również optymalizację w postaci klasyfikacji samych rzeczowników. Takie działanie obniżyło zasoby wymagane podczas przetwarzania oraz znacznie przyspieszyło naukę oraz klasyfikację dokumentów. Co więcej, mimo oczywistej zalety (ograniczenie przetwarzanych danych o 20-30\%), to skuteczność klasyfikacji pozostała praktycznie bez zmian. Takie działanie z pewnością powinno być brane pod uwagę podczas tworzenia systemów przetwarzających i klasyfikujących duże zbiory dokumentów, gdyż jest to relatywnie prosty sposób na optymalizację procesu przetwarzania.  

Podczas badań wykazano, że \textit{fastText} jest często równie dokładny co model \textit{Bag-Of-Words}, a jednocześnie wymaga kilku rzędów wielkości krótszego czasu, aby klasyfikować tekst na zwykłych procesorach. Dodatkowo jego parametry pozwalają na zmniejszenie czasu potrzebnego na naukę kosztem niższej skuteczności. Może być to szczególnie pożądany efekt w systemach, które działają w czasie rzeczywistym, gdzie odpowiedzi na wprowadzone dane powinny być natychmiastowe na nowo wprowadzane dane. Praca z całą pewnością może posłużyć jako punkt odniesienia dla społeczności badawczej, w której rośnie zainteresowanie porównywaniem skuteczności różnych metod klasyfikacji tekstu. 

\section{Możliwe kierunku rozwoju}

\subsubsection*{Rozszerzenie o inne języki naturalne}
Według założeń, klasyfikacja tekstu odbywała się przy wykorzystaniu tekstów w języku polskim. Zaimplementowany system z powodzeniem mógłby zostać użyty wraz z innymi językami naturalnymi. Konieczne wtedy byłyby minimalne zmiany w zakresie wykorzystanych słowników słów nierelewantnych oraz implementacja odpowiedniego analizatora morfologicznego. Rozszerzenie systemu o kolejne języki wymagałoby również dodatkowych parametrów, które informowałyby system o tym, który analizator powinien zostać użyty.

\subsubsection*{Metody klasyfikacji}
Chociaż w pracy przetestowano dwie metody klasyfikacji tekstu, badania mogą być rozszerzone o dodatkową metodę klasyfikacji opartą o LDA (ang. Latent Dirichlet allocation), należącą do metod uczących się bez nauczyciela. W takim przypadku podejście do klasyfikacji musiałoby zostać zmodyfikowane ze względu na sposób działania LDA; należałoby zwrócić też uwagę na to, ile tematów powinno być wygenerowanych przez algorytm, a następnie dopasować jego wyniki do zaimplementowanych już metod.

\subsubsection*{Usprawnienie rozpoznawania kategorii}
Bardzo duża część pobranego korpusu musiała zostać odrzucona ze względu na unikalne kategorie przypisywane do artykułów przez autorów tekstów. Usprawnienie polegałoby na próbie wyszukania bardziej ogólnych tagów/klas/kategorii dla danego artykułu. W pracy brano pod uwagę jedynie kategorie ustalane przez autorów.

\subsubsection*{Rozbudowa korpusu}
Dodatkową ścieżką rozwoju pracy może być również próba rozbudowania istniejącego korpusu z artykułami o dodatkowe klasy. Może to zostać zrealizowane dzięki implementacji klasy \textit{ParserTemplateStep.class} w aplikacji Javowej. Dodanie kolejnych kategorii wzbogaciłoby otrzymywane wyniki.   