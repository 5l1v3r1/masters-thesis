Za dawnych czasów do wydawania poleceń komputerom używano kart perforowanych. Potem przyszły klawiatury, myszki, ekrany dotykowe i polecenia głosowe. Te ostatnie zaczynają mieć jednak tendencję do robienia śmiesznych numerów. Zapewne większość z Was ma pod ręką asystenta (czy też asystentkę) sterowanego głosem. Ma na imię Siri, Google Now lub Cortana. Włączony mikrofon może mieć też konsola lub telewizor. Wygoda obsługi idzie jednak ramię w ramię z różnymi ryzykami. Ciekawy przykład dotarł do nas z USA. Oprócz wymienionych wyżej asystentów największych rynkowych graczy Amerykanie znają także Alexę, stworzoną przez firmę Amazon. Co prawda urządzenia mobilne Amazona dużej części rynku nie zdobyły, jednak głównym przyczółkiem Alexy jest Amazon Echo – czarny cylinder, służący jako bezprzewodowy głośnik i potrafiący sporządzać listy zakupów, serwować aktualności pogodowe czy sportowe i odpowiadać na proste pytania. Da się też go połączyć z domową automatyką i umożliwić głosowe sterowanie ogrzewaniem, oświetleniem i innymi kompatybilnymi urządzeniami Philipsa, Samsunga czy WeMo. Te możliwości stały się powodem śmiesznego incydentu. Urządzenie Amazona Pewna stacja radiowa poinformowała, że emisja jej poprzedniego programu poświęconego własnie Amazon Echo spowodowała reakcję urządzeń w domach słuchaczy. Prowadzący podawał w audycji przykłady poleceń głosowych, w tym między innymi komendy wyłączenia ogrzewania. Niektórzy słuchacze zgłosili się do stacji by przekazać, że ich Alexa polecenia wysłuchała i ogrzewanie wyłączyła. Projektanci urządzeń sterowanych głosem najwyraźniej nie uznali takich sytuacji za szczególnie niebezpieczne. Faktycznie, dzisiaj trudno wyobrazić sobie scenariusz, w którym komuś dzieje się krzywda bo w radiu czy telewizji padła konkretna sekwencja słów. Warto jednak zauważyć, że tego typu anegdoty zaczynają się pojawiać. Już w 2014 reklama telewizyjna włączała konsole w pokojach widzów:  Pomysł wyłączania telefonu przez stację radiową wykorzystała w swojej reklamie Toyota. Zabawny był także przypadek gdy gracz nazwał swoje konto XBOX SIGN OUT, dzięki czemu każdy jego partner lub przeciwnik który wypowiedział na głos jego pseudonim zaskakiwał sam siebie niespodziewanym końcem zabawy. Słyszeliśmy także o próbach trollowania użytkowników dawno już zapomnianego Google Glass serią poleceń „Hey Google, safe search off, image search diarrhea”, lecz nie mamy potwierdzenia, że taki atak miał miejsce i zakończył się powodzeniem (przynajmniej dla atakującego). Problemy z Amazon Echo mają także pracownicy producenta:  Może Wy kojarzycie inne przykłady? Niektórzy producenci próbują już zabezpieczać swoje systemy przed podobnymi zagrożeniami – podobno w najnowszych iPhonach Siri wykonuje tylko polecenia wydane głosem właściciela. O ile w przypadku urządzeń osobistych takich jak telefony komórkowe ma to sens, o tyle np. Amazon Echo musiałby nauczyć się głosów wszystkich domowników upoważnionych do wydawania poleceń, a to już trochę bardziej skomplikowane. Pewnie nie raz jeszcze będziemy mieli okazję opisywać podobne incydenty, szczególnie w dobie telewizorów podsłuchujących wszystkie rozmowy. 2016-03-12 19:00 Artykuł zaktualizowany o kilka przykładów.,Adam