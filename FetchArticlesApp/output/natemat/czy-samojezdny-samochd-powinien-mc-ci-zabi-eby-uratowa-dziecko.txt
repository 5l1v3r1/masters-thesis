Samojezdne samochody to jedno z marzeń ludzkości. Pozwalają uniknąć części nieprzyjemności związanych z prowadzeniem auta, takich jak parkowanie, stanie w korku czy monotonna jazda na autostradzie. To także szansa na automatyzację transportu i poprawę bezpieczeństwa na drogach. Pytanie tylko, w jaki sposób samojezdne samochody zachowają się, żeby uniknąć wypadku? Moralność inteligentnych robotów i innych częściowo autonomicznych maszyn to temat, którym powinniśmy interesować się bardziej. O zagrożeniach związanych z rozwojem sztucznej inteligencji otwarcie mówią już takie autorytety jak Stephen Hawking oraz znani przedsiębiorcy pokroju Elona Muska. Ten drugi twierdzi nawet, że samodzielnie myślące roboty mogą okazać się groźniejszym zagrożeniem niż broń nuklearna. W wypadku samojezdnych samochodów trudno mówić o aż takim zagrożeniu. Wręcz przeciwnie, powinniśmy je raczej rozpatrywać w kategoriach poprawy naszego bezpieczeństwa per saldo. Okazuje się, że autonomiczne auta mają lepszy refleks niż normalni kierowcy oraz, że zachowują bezpieczniejszą odległość między pojazdami niż ludzie. Są zatem lepsze w unikaniu wypadków niż my. Moralność samochodów Ale co jeżeli wypadku nie da się uniknąć? Jak zachowa się samojezdny samochód, kiedy na jezdnię znienacka wyskoczy dziecko i jedyną drogą ucieczki przed potrąceniem młodego człowiek będzie wpakowanie się w drzewo lub do rowu, czego efektem może być śmierć pasażera samochodu? Teoretycznie, pierwsze prawo robotyki głosi, że "robot nie może skrzywdzić człowieka, ani przez zaniechanie działania dopuścić, aby człowiek doznał krzywdy". Tylko, że w tym wypadku musi ocenić czyja krzywda jest ważniejsza. Jego właściciela czy dziecka? Kto ma za to odpowiadać? A co jeśli samojezdny samochód musi stanąć przed wyborem czy zabić lub narazić na szwank jednego pasażera, żeby ochronić grupę pieszych? Czy roboty mają być utylitarystyczne? Czy może za wszelką cenę chronić swoich właścicieli? To bardzo ważne pytania. Jeszcze ważniejszym pytaniem jest to kto powinien zaprogramować moralne decyzje samojezdnych samochodów? Czy mają to określić jego twórcy? A może zaraz po zakupie tego typu auta jego właściciel powinien przejść przez żmudny proces "konfiguracji" moralności swojego pojazdu i określić mu wytyczne jakimi ma się kierować? Jest też jeszcze jedna opcja - uregulują to odgórnie rządowe przepisy. Te pytania nie mogą zostać bez odpowiedzi jeżeli mamy na masową skalę zacząć korzystać z technologi samojezdnych samochodów.,Paweł LutySamojezdne samochody to jedno z marzeń ludzkości. Pozwalają uniknąć części nieprzyjemności związanych z prowadzeniem auta, takich jak parkowanie, stanie w korku czy monotonna jazda na autostradzie. To także szansa na automatyzację transportu i poprawę bezpieczeństwa na drogach. Pytanie tylko, w jaki sposób samojezdne samochody zachowają się, żeby uniknąć wypadku? Moralność inteligentnych robotów i innych częściowo autonomicznych maszyn to temat, którym powinniśmy interesować się bardziej. O zagrożeniach związanych z rozwojem sztucznej inteligencji otwarcie mówią już takie autorytety jak Stephen Hawking oraz znani przedsiębiorcy pokroju Elona Muska. Ten drugi twierdzi nawet, że samodzielnie myślące roboty mogą okazać się groźniejszym zagrożeniem niż broń nuklearna. W wypadku samojezdnych samochodów trudno mówić o aż takim zagrożeniu. Wręcz przeciwnie, powinniśmy je raczej rozpatrywać w kategoriach poprawy naszego bezpieczeństwa per saldo. Okazuje się, że autonomiczne auta mają lepszy refleks niż normalni kierowcy oraz, że zachowują bezpieczniejszą odległość między pojazdami niż ludzie. Są zatem lepsze w unikaniu wypadków niż my. Moralność samochodów Ale co jeżeli wypadku nie da się uniknąć? Jak zachowa się samojezdny samochód, kiedy na jezdnię znienacka wyskoczy dziecko i jedyną drogą ucieczki przed potrąceniem młodego człowiek będzie wpakowanie się w drzewo lub do rowu, czego efektem może być śmierć pasażera samochodu? Teoretycznie, pierwsze prawo robotyki głosi, że "robot nie może skrzywdzić człowieka, ani przez zaniechanie działania dopuścić, aby człowiek doznał krzywdy". Tylko, że w tym wypadku musi ocenić czyja krzywda jest ważniejsza. Jego właściciela czy dziecka? Kto ma za to odpowiadać? A co jeśli samojezdny samochód musi stanąć przed wyborem czy zabić lub narazić na szwank jednego pasażera, żeby ochronić grupę pieszych? Czy roboty mają być utylitarystyczne? Czy może za wszelką cenę chronić swoich właścicieli? To bardzo ważne pytania. Jeszcze ważniejszym pytaniem jest to kto powinien zaprogramować moralne decyzje samojezdnych samochodów? Czy mają to określić jego twórcy? A może zaraz po zakupie tego typu auta jego właściciel powinien przejść przez żmudny proces "konfiguracji" moralności swojego pojazdu i określić mu wytyczne jakimi ma się kierować? Jest też jeszcze jedna opcja - uregulują to odgórnie rządowe przepisy. Te pytania nie mogą zostać bez odpowiedzi jeżeli mamy na masową skalę zacząć korzystać z technologi samojezdnych samochodów.,Paweł Luty