Jak ocenić znaczenie badań naukowych? Jak zmierzyć jakość odkrycia? Jak odsiać doświadczalne ziarna od plew? Na świecie prowadzi się coraz to więcej i więcej badań naukowych, a powszechny dostęp do infomacji - i publikacji - przez internet sprawia, że zalewa nas fala doniesień o coraz to nowych odkryciach. Świat nauki ma jednak kilka metod, które pozwolą nam ocenić, czy badania, o których czytamy tu i tam, są warte rozgłosu, czy funta kłaków nie warte. Najpowszechniej stosowaną zaś jest wskaźnik opracowany przez Institute for Scientific Information, znany pod angielską nazwą impact factor. , gdyby miał polską nazwę, nazywałby się zapewne wskaźnikiem wpływu. Bo i to właśnie mierzy - wpływ, jaki wyniki danych badań mają na dalszy rozwój nauki. Jak to robi? W najprostszy możliwy sposób: sprawdzając, jak często cytowana jest dana praca. Bo im cześciej jest cytowana, tym bardziej jest popularna, tym większa liczba badaczy ją przeczytała i być może się zainspirowała. To jest jednak bardzo uproszczone postawienie sprawy. nie mierzy bowiem cytowalności poszczególnych publikacji - jest on obliczany dla całych pism. Może się więc zdarzyć, że publikacja mierna trafi jakimś cudem do pisma o wysokim - podnosząc tym samym prestiż autora (bo łatwiej wówczas o finansowanie), ale nie wpływając znacząco na prestiż pisma. Ale działać może to i w drugą stronę - jedna dobrze ulokowana publikacja może odmienić oblicze żurnala. Ale o tym za moment. jest wskaźnikiem aktualnym - obliczany jest przez (firmę, która przejęła ISI) corocznie, na podstawie cytowań z dwóch poprzednich lat. Jego wartość dla różnych pism dobrze zatem obrazuje aktualne trendy w nauce. Te publikujące interesujące badania, przyciągające uwagę wielu badaczy, będą bowiem cytowane często i gęsto, zaś pisma będzie rósł. Nie wszyscy jednak są z takiego stanu rzeczy zadowoleni, ze wspomnianego już wcześniej powodu: bowiem wskaźnik ten mówi nam o jakości pisma, nie zaś poszczególnych publikacji. Stąd też biorą się próby opracowania podobnych wskaźników, które lepiej opisywałyby naukową rzeczywistość. Jednym z takim wskaźników jest indeks Hirscha, który - w uproszczeniu - pozwala określić znaczenie prac naukowych badacza. Jest on z pewnością nieco lepszym narzędziem opsiującym dorobek badacze, ale idealny też nie jest. Nie uwzględnia on bowiem wielu czynników: dlaczego, dla przykładu, praca była cytowana (bo mogła być równie dlatego, że zawierała bzdury); którym autorem pracy był badacz; ile prac dany badacz opublikował. Indeks Hirscha można w dodatku łatwo zmanipulować poprzez autocytowanie: czyli cytowanie własnych prac. Ale i nie jest wolny od tego typu problemów. I tu dochodzimy do dwóch przykładów, o których dzisiaj chciałem w zasadzie opowiedzieć. Pierwszy przykład pochodzi sprzed pięciu lat. W 2007 roku redaktorzy fachowego pisma medycznego o dźwięcznej nazwie postanowili zaprotestować przeciwko stosowaniu wszędzie i jako lekarstwo na każdą bolączkę. Bo jak już wspomniałem, , chociać dostarcza nam sporo informacji, idealny jednak nie jest; nadużywany zaś jest do wywierania nacisku finansowego i prestiżowego na badaczy. W ramach protestu redaktorzy pisma napisali krótką notkę, w której zacytowali wszystkie artykuły opublikowane w żurnalu w poprzednich dwóch latach. Na skutek tego autocytowania IF pisma wzrósł z 0.66 do 1.44 w roku kolejnym. Protest poskutkował jednak głównie tym, że postanowił wykluczyć pismo z klasyfikacji w dwóch kolejnych latach. Ot i padła rebelia. Drugi przykład tego, jak można zmanipulować jest nieco tylko świeższy. W 2008 roku , pismo publikujące najważniejsze doniesienia z dziedziny krystalografii, opublikowało pracę przeglądową George'a Sheldricka z uczelni w Goettingen dotyczącą historii SHELX. SHELX to open-source'owy program rozwijany przez Sheldricka już od lat 60. poprzedniego stulecia, bardzo powszechnie stosowany przez krystalografów. Sheldrick w swojej przeglądówce umieścił zaś następujące zdanie: To mniej więcej tak, jak gdyby Bill Gates opublikował króciutką pracę o, weźmy na to, początkach Microsoftu, a na końcu napisał: gdy użytkownik w czasie opisywanych badań korzysta z OS Windows, niniejsza praca może być cytowana jako literatura przedmiotu. Publikacja poskutkowała tym, że , które do tej pory miało przyzwoity jak na niszowe pismo IF nieco powyżej dwóch, w 2009 roku poszybowało. I to poszybowało wysoko do wartości blisko 50, z piedestału spychając np. (w 2009 - 31.434), (28.103), a nawet , który zazwyczaj plasuje się na drugim miejscu pośród pism o najwyższym IF (47.050). Jedyne pismo, którego pozycja nie została zagrożona to , którego IF w 2009 sięgał blisko 88, obecnie zaś wynosi ponad 94. W tym jednak przypadku liczyć można na sprzężenie zrotne systemu. Jeśli nie opublikuje (a raczej już nie opublikowało) artykułu, który wywołałby podobną lawinę cytowań jak praca Sheldricka, w raporcie cytowań na obecny rok - który ukaże się jednak dopiero w lecie przyszłego roku - pismo prawdopodobnie wróci do swojego uprzedniego poziomu. Może więc nie jest wskaźnikiem idealnym, ale jak się nie ma, co się lubi, to się lubi, co się ma. A idealnego miernika znaczenia i wpływu publikacji jeszcze nikt nie wymyślił. No, może poza Noblem, ale też i jest ten wskaźnik ograniczony do kilku zaledwie dziedzin, a w nich do trzech tylko osób rocznie...,Rafał MarszałekJak ocenić znaczenie badań naukowych? Jak zmierzyć jakość odkrycia? Jak odsiać doświadczalne ziarna od plew? Na świecie prowadzi się coraz to więcej i więcej badań naukowych, a powszechny dostęp do infomacji - i publikacji - przez internet sprawia, że zalewa nas fala doniesień o coraz to nowych odkryciach. Świat nauki ma jednak kilka metod, które pozwolą nam ocenić, czy badania, o których czytamy tu i tam, są warte rozgłosu, czy funta kłaków nie warte. Najpowszechniej stosowaną zaś jest wskaźnik opracowany przez Institute for Scientific Information, znany pod angielską nazwą impact factor. , gdyby miał polską nazwę, nazywałby się zapewne wskaźnikiem wpływu. Bo i to właśnie mierzy - wpływ, jaki wyniki danych badań mają na dalszy rozwój nauki. Jak to robi? W najprostszy możliwy sposób: sprawdzając, jak często cytowana jest dana praca. Bo im cześciej jest cytowana, tym bardziej jest popularna, tym większa liczba badaczy ją przeczytała i być może się zainspirowała. To jest jednak bardzo uproszczone postawienie sprawy. nie mierzy bowiem cytowalności poszczególnych publikacji - jest on obliczany dla całych pism. Może się więc zdarzyć, że publikacja mierna trafi jakimś cudem do pisma o wysokim - podnosząc tym samym prestiż autora (bo łatwiej wówczas o finansowanie), ale nie wpływając znacząco na prestiż pisma. Ale działać może to i w drugą stronę - jedna dobrze ulokowana publikacja może odmienić oblicze żurnala. Ale o tym za moment. jest wskaźnikiem aktualnym - obliczany jest przez (firmę, która przejęła ISI) corocznie, na podstawie cytowań z dwóch poprzednich lat. Jego wartość dla różnych pism dobrze zatem obrazuje aktualne trendy w nauce. Te publikujące interesujące badania, przyciągające uwagę wielu badaczy, będą bowiem cytowane często i gęsto, zaś pisma będzie rósł. Nie wszyscy jednak są z takiego stanu rzeczy zadowoleni, ze wspomnianego już wcześniej powodu: bowiem wskaźnik ten mówi nam o jakości pisma, nie zaś poszczególnych publikacji. Stąd też biorą się próby opracowania podobnych wskaźników, które lepiej opisywałyby naukową rzeczywistość. Jednym z takim wskaźników jest indeks Hirscha, który - w uproszczeniu - pozwala określić znaczenie prac naukowych badacza. Jest on z pewnością nieco lepszym narzędziem opsiującym dorobek badacze, ale idealny też nie jest. Nie uwzględnia on bowiem wielu czynników: dlaczego, dla przykładu, praca była cytowana (bo mogła być równie dlatego, że zawierała bzdury); którym autorem pracy był badacz; ile prac dany badacz opublikował. Indeks Hirscha można w dodatku łatwo zmanipulować poprzez autocytowanie: czyli cytowanie własnych prac. Ale i nie jest wolny od tego typu problemów. I tu dochodzimy do dwóch przykładów, o których dzisiaj chciałem w zasadzie opowiedzieć. Pierwszy przykład pochodzi sprzed pięciu lat. W 2007 roku redaktorzy fachowego pisma medycznego o dźwięcznej nazwie postanowili zaprotestować przeciwko stosowaniu wszędzie i jako lekarstwo na każdą bolączkę. Bo jak już wspomniałem, , chociać dostarcza nam sporo informacji, idealny jednak nie jest; nadużywany zaś jest do wywierania nacisku finansowego i prestiżowego na badaczy. W ramach protestu redaktorzy pisma napisali krótką notkę, w której zacytowali wszystkie artykuły opublikowane w żurnalu w poprzednich dwóch latach. Na skutek tego autocytowania IF pisma wzrósł z 0.66 do 1.44 w roku kolejnym. Protest poskutkował jednak głównie tym, że postanowił wykluczyć pismo z klasyfikacji w dwóch kolejnych latach. Ot i padła rebelia. Drugi przykład tego, jak można zmanipulować jest nieco tylko świeższy. W 2008 roku , pismo publikujące najważniejsze doniesienia z dziedziny krystalografii, opublikowało pracę przeglądową George'a Sheldricka z uczelni w Goettingen dotyczącą historii SHELX. SHELX to open-source'owy program rozwijany przez Sheldricka już od lat 60. poprzedniego stulecia, bardzo powszechnie stosowany przez krystalografów. Sheldrick w swojej przeglądówce umieścił zaś następujące zdanie: To mniej więcej tak, jak gdyby Bill Gates opublikował króciutką pracę o, weźmy na to, początkach Microsoftu, a na końcu napisał: gdy użytkownik w czasie opisywanych badań korzysta z OS Windows, niniejsza praca może być cytowana jako literatura przedmiotu. Publikacja poskutkowała tym, że , które do tej pory miało przyzwoity jak na niszowe pismo IF nieco powyżej dwóch, w 2009 roku poszybowało. I to poszybowało wysoko do wartości blisko 50, z piedestału spychając np. (w 2009 - 31.434), (28.103), a nawet , który zazwyczaj plasuje się na drugim miejscu pośród pism o najwyższym IF (47.050). Jedyne pismo, którego pozycja nie została zagrożona to , którego IF w 2009 sięgał blisko 88, obecnie zaś wynosi ponad 94. W tym jednak przypadku liczyć można na sprzężenie zrotne systemu. Jeśli nie opublikuje (a raczej już nie opublikowało) artykułu, który wywołałby podobną lawinę cytowań jak praca Sheldricka, w raporcie cytowań na obecny rok - który ukaże się jednak dopiero w lecie przyszłego roku - pismo prawdopodobnie wróci do swojego uprzedniego poziomu. Może więc nie jest wskaźnikiem idealnym, ale jak się nie ma, co się lubi, to się lubi, co się ma. A idealnego miernika znaczenia i wpływu publikacji jeszcze nikt nie wymyślił. No, może poza Noblem, ale też i jest ten wskaźnik ograniczony do kilku zaledwie dziedzin, a w nich do trzech tylko osób rocznie...,Rafał MarszałekJak ocenić znaczenie badań naukowych? Jak zmierzyć jakość odkrycia? Jak odsiać doświadczalne ziarna od plew? Na świecie prowadzi się coraz to więcej i więcej badań naukowych, a powszechny dostęp do infomacji - i publikacji - przez internet sprawia, że zalewa nas fala doniesień o coraz to nowych odkryciach. Świat nauki ma jednak kilka metod, które pozwolą nam ocenić, czy badania, o których czytamy tu i tam, są warte rozgłosu, czy funta kłaków nie warte. Najpowszechniej stosowaną zaś jest wskaźnik opracowany przez Institute for Scientific Information, znany pod angielską nazwą impact factor. , gdyby miał polską nazwę, nazywałby się zapewne wskaźnikiem wpływu. Bo i to właśnie mierzy - wpływ, jaki wyniki danych badań mają na dalszy rozwój nauki. Jak to robi? W najprostszy możliwy sposób: sprawdzając, jak często cytowana jest dana praca. Bo im cześciej jest cytowana, tym bardziej jest popularna, tym większa liczba badaczy ją przeczytała i być może się zainspirowała. To jest jednak bardzo uproszczone postawienie sprawy. nie mierzy bowiem cytowalności poszczególnych publikacji - jest on obliczany dla całych pism. Może się więc zdarzyć, że publikacja mierna trafi jakimś cudem do pisma o wysokim - podnosząc tym samym prestiż autora (bo łatwiej wówczas o finansowanie), ale nie wpływając znacząco na prestiż pisma. Ale działać może to i w drugą stronę - jedna dobrze ulokowana publikacja może odmienić oblicze żurnala. Ale o tym za moment. jest wskaźnikiem aktualnym - obliczany jest przez (firmę, która przejęła ISI) corocznie, na podstawie cytowań z dwóch poprzednich lat. Jego wartość dla różnych pism dobrze zatem obrazuje aktualne trendy w nauce. Te publikujące interesujące badania, przyciągające uwagę wielu badaczy, będą bowiem cytowane często i gęsto, zaś pisma będzie rósł. Nie wszyscy jednak są z takiego stanu rzeczy zadowoleni, ze wspomnianego już wcześniej powodu: bowiem wskaźnik ten mówi nam o jakości pisma, nie zaś poszczególnych publikacji. Stąd też biorą się próby opracowania podobnych wskaźników, które lepiej opisywałyby naukową rzeczywistość. Jednym z takim wskaźników jest indeks Hirscha, który - w uproszczeniu - pozwala określić znaczenie prac naukowych badacza. Jest on z pewnością nieco lepszym narzędziem opsiującym dorobek badacze, ale idealny też nie jest. Nie uwzględnia on bowiem wielu czynników: dlaczego, dla przykładu, praca była cytowana (bo mogła być równie dlatego, że zawierała bzdury); którym autorem pracy był badacz; ile prac dany badacz opublikował. Indeks Hirscha można w dodatku łatwo zmanipulować poprzez autocytowanie: czyli cytowanie własnych prac. Ale i nie jest wolny od tego typu problemów. I tu dochodzimy do dwóch przykładów, o których dzisiaj chciałem w zasadzie opowiedzieć. Pierwszy przykład pochodzi sprzed pięciu lat. W 2007 roku redaktorzy fachowego pisma medycznego o dźwięcznej nazwie postanowili zaprotestować przeciwko stosowaniu wszędzie i jako lekarstwo na każdą bolączkę. Bo jak już wspomniałem, , chociać dostarcza nam sporo informacji, idealny jednak nie jest; nadużywany zaś jest do wywierania nacisku finansowego i prestiżowego na badaczy. W ramach protestu redaktorzy pisma napisali krótką notkę, w której zacytowali wszystkie artykuły opublikowane w żurnalu w poprzednich dwóch latach. Na skutek tego autocytowania IF pisma wzrósł z 0.66 do 1.44 w roku kolejnym. Protest poskutkował jednak głównie tym, że postanowił wykluczyć pismo z klasyfikacji w dwóch kolejnych latach. Ot i padła rebelia. Drugi przykład tego, jak można zmanipulować jest nieco tylko świeższy. W 2008 roku , pismo publikujące najważniejsze doniesienia z dziedziny krystalografii, opublikowało pracę przeglądową George'a Sheldricka z uczelni w Goettingen dotyczącą historii SHELX. SHELX to open-source'owy program rozwijany przez Sheldricka już od lat 60. poprzedniego stulecia, bardzo powszechnie stosowany przez krystalografów. Sheldrick w swojej przeglądówce umieścił zaś następujące zdanie: To mniej więcej tak, jak gdyby Bill Gates opublikował króciutką pracę o, weźmy na to, początkach Microsoftu, a na końcu napisał: gdy użytkownik w czasie opisywanych badań korzysta z OS Windows, niniejsza praca może być cytowana jako literatura przedmiotu. Publikacja poskutkowała tym, że , które do tej pory miało przyzwoity jak na niszowe pismo IF nieco powyżej dwóch, w 2009 roku poszybowało. I to poszybowało wysoko do wartości blisko 50, z piedestału spychając np. (w 2009 - 31.434), (28.103), a nawet , który zazwyczaj plasuje się na drugim miejscu pośród pism o najwyższym IF (47.050). Jedyne pismo, którego pozycja nie została zagrożona to , którego IF w 2009 sięgał blisko 88, obecnie zaś wynosi ponad 94. W tym jednak przypadku liczyć można na sprzężenie zrotne systemu. Jeśli nie opublikuje (a raczej już nie opublikowało) artykułu, który wywołałby podobną lawinę cytowań jak praca Sheldricka, w raporcie cytowań na obecny rok - który ukaże się jednak dopiero w lecie przyszłego roku - pismo prawdopodobnie wróci do swojego uprzedniego poziomu. Może więc nie jest wskaźnikiem idealnym, ale jak się nie ma, co się lubi, to się lubi, co się ma. A idealnego miernika znaczenia i wpływu publikacji jeszcze nikt nie wymyślił. No, może poza Noblem, ale też i jest ten wskaźnik ograniczony do kilku zaledwie dziedzin, a w nich do trzech tylko osób rocznie...,Rafał Marszałek