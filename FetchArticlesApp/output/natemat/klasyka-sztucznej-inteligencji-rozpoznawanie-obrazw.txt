Zapraszam na kolejną "wyspę" w opisywanym tu archipelagu sztucznej inteligencji. Dzisiaj zajmiemy się zbiorem metod nazywanych w Polsce rozpoznawaniem obrazów, chociaż angielski odpowiednik tej nazwy "pattern recognition", czyli "rozpoznawanie wzorców" - lepiej oddaje rzeczywisty zakres rozważanych zagadnień. Badane i rozwijane są bowiem metody rozpoznawania WSZYSTKIEGO: obrazów, dźwięków (m.in. mowy), chorób (w celu wspomagania diagnostyki medycznej), sytuacji ekonomicznej (w celu optymalizacji decyzji finansowych), formacji geologicznych (w celu znajdowania nowych złóż surowców), nastrojów społecznych (w celu przewidywania wyników wyborów) itd. Warto poznać te metody! Wspomniane wyżej uogólnienia będą jednak omówione w osobnym wpisie za kilka dni, wygodnie będzie bowiem teraz przedstawić metody rozpoznawania obrazów na przykładzie ... obrazów jako takich: zdjęć, kadrów filmowych, zobrazowań medycznych, obrazów satelitarnych itp. Od tego więc zaczniemy. O zadaniu rozpoznawania obrazów jako o jednym z pierwszych problemów podejmowanych i rozwiązywanych w ramach sztucznej inteligencji była już mowa w tym blogu, gdy opisywałem Perceptron. Teraz jednak skupimy się na tym zadaniu nieco dokładniej. Zadania rozpoznawania obrazów występujące w codziennym życiu zwykle nie stanowią żadnego problemu dla człowieka. Wystarczy rzut oka - i już rozpoznajemy znajomą osobę, znany przedmiot, widywany krajobraz. Natomiast to samo zadanie dla komputera okazuje się bardzo trudne. A tymczasem potrzebujemy komputerów rozpoznających obrazy. Człowiek jest wzrokowcem i całe swoje otoczenie tak zorganizował, że najważniejsze informacje pozyskujemy za pomocą wzroku. Tak działamy w pracy, w domu i w podróży. Większość decyzji podejmujemy na podstawie tego, co widzimy! Jeśli chcemy, żeby maszyny skuteczniej pomagały nam w pracy, jeśli czekamy na robota, który będzie nas wyręczał w pracach domowych, jeśli chcemy mieć auto, które zawiezie nas bezpiecznie bez kierowcy do wymaganego miejsca - to musimy mieć komputery rozpoznające obrazy. Piszę "komputery" mając na myśli nie tylko laptopy czy komputery stacjonarne, ale także te komputery, które już są "sercem" nowoczesnych systemów produkcyjnych, które będą "mózgiem" domowego robota, czy które prędzej czy później pojawią się w samochodach. One wszystkie potrzebują umiejętności rozpoznawania obrazów. Tymczasem my ciągle nie potrafimy im tej umiejętności podarować. Na przykład, do dziś nie mamy skutecznych programów rozpoznających ludzi na podstawie ich twarzy, sylwetki, sposobu zachowania itd. Dla nas jest to dziecinnie proste. Ale komputer bardzo się z tym biedzi i często popełnia błędy. A przecież gdyby komputery umiały rozpoznawać ludzi,i to można by było zrezygnować z niewygodnych kart identyfikacyjnych, pinów, haseł , kluczy itp. Bankomat wypłacałby pieniądze na podstawie obrazu twarzy osoby, samochód otwierałby drzwi widząc nadchodzącego właściciela, wejście do mieszkania z rękami pełnymi zakupów byłoby łatwe i wygodne, bo zamiast szukać klucza wystarczyłoby pokazać do kamery buzię... Dlaczego to stale jest w sferze marzeń? Żeby odpowiedzieć na to pytanie rozważmy, jak powinien działać system rozpoznawania. Istota rozpoznawania polega na zamianie obrazu na decyzję. Początek jest łatwy, bo proces pozyskiwania cyfrowych obrazów opanowaliśmy obecnie do perfekcji - robi to każdy aparat fotograficzny, którego budowę i działanie omówiłem wcześniej. Ale potem trzeba zarejestrowany cyfrowo zbiór punktów obrazu (tak zwanych pikseli) zamienić na decyzję. I to nie jest łatwe! Metodami matematycznymi służącymi do tego celu zajmowałem się od wielu lat - początkowo studiując (i tłumacząc na język polski) książki innych autorów. Potem jednak rozpocząłem w tej dziedzinie własne badania naukowe (napisałem ponad sto artykułów o wynikach tych badań) i starałem się ją spopularyzować w różnych kręgach pisząc własne książki. Były to jednak książki naukowe i chociaż są one obecnie dostępne w sieci - nie będę do nich odsyłał, bo ich studiowanie wymaga pewnego wysiłku. Zamiast tego spróbuję o tym wszystkim jasno i przystępnie odpowiedzieć, licząc na to, że uda mi się Państwa zainteresować. Zacznę od spojrzenia na całość problemu. Proces automatycznego rozpoznawania obrazu składa się z czterech etapów, przedstawionych (trochę żartobliwie...) na rysunku poniżej. Rysunek nawiązuje do tego podobszaru problematyki rozpoznawania obrazów, którym się obecnie zajmuję - to znaczy obrazowania medycznego, ale ogólny schemat jest uniwersalny i dotyczy wszelkich zastosowań rozpoznawania. Pierwszym etapem jest pozyskanie obrazu. Przy zwykłych obrazach jest to banalne - wystarczy dowolny aparat fotograficzny lub nawet zwykła komórka - i już mamy obraz cyfrowy. W przypadku obrazów medycznych, zwłaszcza dotyczących wnętrza ciała człowieka, konieczne jest użycie specjalnej aparatury, ale tym się teraz zajmować nie będziemy. Potem następuje analiza i określenie cech obrazu. To bardzo ważny etap, gdyż algorytmy opisu obrazy nie mogą (na ogół) zmagać się z milionami pikseli składającymi się na oryginalny obraz, tylko muszą dostać wygodną do interpretacji reprezentację obrazu w postaci pojedynczego punktu w przestrzeni cech. Zajmiemy się tym dokładniej za chwilę. Kolejnym etapem jest znalezienie właściwego opisu obrazu w postaci odpowiednio dobranej formuły matematycznej. Tu jest mnóstwo różnych możliwości, gdyż w toku ponad ćwierć wieku rozwoju tej problematyki wielu badaczy proponowało różne formy tego opisu i różne wynikające z nich algorytmy postępowania. O niektórych z nich napiszę dalej. No i na koniec następuje właściwe rozpoznanie obrazu i związana z nim decyzja. Wbrew pozorom jest to najłatwiejsza część zadania, bo po dobrym określeniu cech obrazu i po jego porządnym matematycznym opisaniu - podjęcie decyzji jest w istocie czynnością elementarną. Przejdźmy teraz do szczegółów. Po uzyskaniu obrazu staramy się znaleźć zestaw cech, które można automatycznie wyznaczyć na obrazie, a które na tyle dobrze charakteryzują rozpoznawane obiekty, że mając do dyspozycji same tylko cechy - można te obiekty rozpoznać. Rozpoznawanie silnie zależy od tego, jakich cech użyto do scharakteryzowania obiektu, dlatego ich wybór musi być dokładnie przemyślany. Najwygodniej jest, gdy uda się przypisać do rozpoznawanych obiektów cechy o charakterze ilościowym, to znaczy takie, które dadzą się zmierzyć, wyrazić ilościowo i odłożyć na osiach układu współrzędnych tak zwanej przestrzeni cech. Rozważmy zadanie rozpoznawania, w którym rozpoznawanymi obiektami są ludzkie twarze. Możemy każdą twarz scharakteryzować przez zmierzenie jej szerokości, wielkości ust i rozstawu oczu. Jeśli dla konkretnego obiektu (twarzy) zmierzymy te cechy i odłożymy ich wartości odpowiednio na osiach trójwymiarowego układu współrzędnych - to w przestrzeni opisywanej przez te cechy wyznaczymy pewien punkt, który może w dalszych rozważaniach reprezentować ten konkretny obiekt. Jeśli rozważymy zbiór obiektów, to każdemu obiektowi przyporządkowany będzie pewien punkt w przestrzeni cech. Położenie tego punktu będzie identyfikowało dany obiekt i pozwoli odróżnić go od innych obiektów. Strukturę rozważanej przestrzeni cech obrazuje rysunek, na którym zaznaczyłem szkice twarzy o krańcowych wartościach rozważanych cech. Przestrzeń cech (jeśli jest dobrze zbudowana) ma tę miłą właściwość, że różne obrazy twarzy tego samego człowieka będą wyznaczały punkty położone blisko siebie w tej przestrzeni, podczas gdy obrazy przedstawiające twarze innych ludzi będą położone w innym jej obszarze. Własność ta znacząco ułatwia dalsze etapy procesu rozpoznawania. W przypadku rozpoznawania twarzy, różne wizerunki twarzy tego samego człowieka powinny być rozpoznawane jako należące do jednej klasy, prowadzącej do jednej konkretnej decyzji (na przykład ). Różne obrazy twarzy tego samego człowieka obiektywnie różnią się od siebie, bo człowiek raz jest poważny, innym razem wesoły, może mieć dłuższe albo krótsze włosy, może być różnie ubrany (włączając w to nakrycie głowy), może patrzeć wprost w kamerę, albo ustawiać się profilem itd. Wszystkie te obrazy są jednak utożsamiane z tym samym rozpoznaniem () i z tą samą decyzją. Jednak w większości zastosowań rozpoznawaną klasą jest zbiór wszystkich obrazów obiektów, które mają jakieś istotne cechy wspólne, prowadzące do tej samej decyzji końcowej (takiego samego rozpoznania). Jako przykład możemy rozważyć zbiór wszystkich liter A odczytywanych ze skanowanych dokumentów. Obrazy tych liter mogą być różne, bo różne są kształty czcionki używanej do druku, różna jest ich wielkość, różny kolor, różne tło itd. - ale zawsze na podstawie takiego obrazu powinna być podjęta ta sama decyzji końcowa: . Jako inny przykład można wymienić (w zastosowaniu do diagnostyki medycznej) zbiór osób chorych na grypę. Chociaż niewątpliwie każdy pacjent ma swoje indywidualne cechy, to jednak są też cechy pozwalające na przypisanie tych wszystkich pacjentów do klasy oraz umożliwiających ich odróżnienie od osób zdrowych lub cierpiących na inne choroby. W opisanej wyżej przestrzeni cech obiekty należące do tej samej klasy tworzą skupienie dobrze odseparowane (odległe) od skupień reprezentujących obiekty innych klas. Takie grupowanie obiektów należących do jednej klasy w przestrzeni cech jest warunkiem koniecznym skutecznego rozpoznawania. Jeśli w przestrzeni cech obiekty ulegają wymieszaniu - to żadna metoda nie zapewni ich skutecznego rozpoznawania. Po określeniu cech obrazu powinien nastąpić jego opis. Przedstawiając ten etap procesu rozpoznawania jestem trochę w kłopocie, bo powinienem odwołać się do matematycznego pojęcia funkcji przynależności - a trudno jest to zrobić nie wypisując żadnych wzorów. Ale spróbuję... Funkcje przynależności pełnią podobną rolę w rozpoznawaniu obrazów, jak omawiane wcześniej funkcje przynależności w teorii zbiorów rozmytych. Jednak te funkcje przynależności, których używamy w rozpoznawaniu obrazów muszą być tworzone automatycznie przez algorytm rozpoznający na podstawie procesu uczenia. Z procesem tym spotkaliśmy się już przy omawianiu właściwości Perceptronu a także przy przedstawianiu bardzo wydajnych narzędzi sztucznej inteligencji, jakimi są sieci neuronowe. Uczenie algorytmu rozpoznającego powinno doprowadzić do tego, by w każdym punkcie przestrzeni cech dla każdej z rozpoznawanych klas obrazów można było określić, jak bardzo obiekt związany z tym właśnie punktem przestrzeni zasługuje na to, żeby można go było zaliczyć do tej właśnie klasy. Na rysunku pokazano przykładowo funkcje przynależności zbudowane dla dwóch klas w dwuwymiarowej przestrzeni cech. W rzeczywistych zadaniach rozpoznawania przestrzeń cech bywa wielowymiarowa, a rozpoznawanych klas bywa kilkadziesiąt, więc budowa funkcji przynależności nie jest zadaniem łatwym. Ale są wypracowane metody, które pozwalają to skutecznie robić nawet dla bardzo skomplikowanych zadań. Często zresztą upraszczamy zadanie i zamiast budować funkcje przynależności poszukujemy funkcji, które mogą opisywać w przestrzeni cech granice pomiędzy skupieniami poszczególnych klas. Jest to szczególnie łatwe, jeśli taka granica jest linią prostą (w przestrzeni dwuwymiarowej ) lub płaszczyzną (w przestrzeni o większej liczbie wymiarów). Nie zawsze jednak to się udaje, jak widać na rysunku po prawej stronie... Przy dobrze zbudowanym zbiorze funkcji przynależności (dla wszystkich rozpoznawanych klas!) lub przy dobrze opisanych granicach pomiędzy klasami - ostatni etap procesu rozpoznawania (rozpoznanie i decyzja) jest już łatwy. Po prostu rozpoznawany obiekt zalicza się do tej klasy, której funkcja przynależności obliczona dla tego obiektu daje największą wartość. Alternatywnie można decyzję podjąć na podstawie tego, po której stronie linii granicznej znalazł się w przestrzeni cech punkt reprezentujący rozpoznawany obiekt. Oczywiście można mnożyć wymagania, na przykład żądać tego, żeby wartość funkcji przynależności wybranej klasy dość wyraźnie dominowała nad wartościami funkcji przynależności dla "konkurencyjnych" klas itd. Ale to są już detale, nie warte szczegółowej dyskusji w tym popularnym opracowaniu. Na koniec dodam, że w prostych przypadkach rozpoznawanie można przeprowadzać także bez formalnego obliczania funkcji przynależności na podstawie prostej intuicji "". Jeśli w przestrzeni cech mamy punkty pochodzące ze zbioru uczącego (to znaczy lokalizacje obiektów, których przynależność do określonych klas jest znana) i pojawia się nowy obiekt, którego przynależność trzeba dopiero określić, to najprościej jest zaliczyć go do tej klasy, do której należą obiekty zbioru uczącego, leżące najbliżej nieznanego (rozpoznawanego) obiektu. Jest to proste i często wystarczająco skuteczne!,Ryszard TadeusiewiczZapraszam na kolejną "wyspę" w opisywanym tu archipelagu sztucznej inteligencji. Dzisiaj zajmiemy się zbiorem metod nazywanych w Polsce rozpoznawaniem obrazów, chociaż angielski odpowiednik tej nazwy "pattern recognition", czyli "rozpoznawanie wzorców" - lepiej oddaje rzeczywisty zakres rozważanych zagadnień. Badane i rozwijane są bowiem metody rozpoznawania WSZYSTKIEGO: obrazów, dźwięków (m.in. mowy), chorób (w celu wspomagania diagnostyki medycznej), sytuacji ekonomicznej (w celu optymalizacji decyzji finansowych), formacji geologicznych (w celu znajdowania nowych złóż surowców), nastrojów społecznych (w celu przewidywania wyników wyborów) itd. Warto poznać te metody! Wspomniane wyżej uogólnienia będą jednak omówione w osobnym wpisie za kilka dni, wygodnie będzie bowiem teraz przedstawić metody rozpoznawania obrazów na przykładzie ... obrazów jako takich: zdjęć, kadrów filmowych, zobrazowań medycznych, obrazów satelitarnych itp. Od tego więc zaczniemy. O zadaniu rozpoznawania obrazów jako o jednym z pierwszych problemów podejmowanych i rozwiązywanych w ramach sztucznej inteligencji była już mowa w tym blogu, gdy opisywałem Perceptron. Teraz jednak skupimy się na tym zadaniu nieco dokładniej. Zadania rozpoznawania obrazów występujące w codziennym życiu zwykle nie stanowią żadnego problemu dla człowieka. Wystarczy rzut oka - i już rozpoznajemy znajomą osobę, znany przedmiot, widywany krajobraz. Natomiast to samo zadanie dla komputera okazuje się bardzo trudne. A tymczasem potrzebujemy komputerów rozpoznających obrazy. Człowiek jest wzrokowcem i całe swoje otoczenie tak zorganizował, że najważniejsze informacje pozyskujemy za pomocą wzroku. Tak działamy w pracy, w domu i w podróży. Większość decyzji podejmujemy na podstawie tego, co widzimy! Jeśli chcemy, żeby maszyny skuteczniej pomagały nam w pracy, jeśli czekamy na robota, który będzie nas wyręczał w pracach domowych, jeśli chcemy mieć auto, które zawiezie nas bezpiecznie bez kierowcy do wymaganego miejsca - to musimy mieć komputery rozpoznające obrazy. Piszę "komputery" mając na myśli nie tylko laptopy czy komputery stacjonarne, ale także te komputery, które już są "sercem" nowoczesnych systemów produkcyjnych, które będą "mózgiem" domowego robota, czy które prędzej czy później pojawią się w samochodach. One wszystkie potrzebują umiejętności rozpoznawania obrazów. Tymczasem my ciągle nie potrafimy im tej umiejętności podarować. Na przykład, do dziś nie mamy skutecznych programów rozpoznających ludzi na podstawie ich twarzy, sylwetki, sposobu zachowania itd. Dla nas jest to dziecinnie proste. Ale komputer bardzo się z tym biedzi i często popełnia błędy. A przecież gdyby komputery umiały rozpoznawać ludzi,i to można by było zrezygnować z niewygodnych kart identyfikacyjnych, pinów, haseł , kluczy itp. Bankomat wypłacałby pieniądze na podstawie obrazu twarzy osoby, samochód otwierałby drzwi widząc nadchodzącego właściciela, wejście do mieszkania z rękami pełnymi zakupów byłoby łatwe i wygodne, bo zamiast szukać klucza wystarczyłoby pokazać do kamery buzię... Dlaczego to stale jest w sferze marzeń? Żeby odpowiedzieć na to pytanie rozważmy, jak powinien działać system rozpoznawania. Istota rozpoznawania polega na zamianie obrazu na decyzję. Początek jest łatwy, bo proces pozyskiwania cyfrowych obrazów opanowaliśmy obecnie do perfekcji - robi to każdy aparat fotograficzny, którego budowę i działanie omówiłem wcześniej. Ale potem trzeba zarejestrowany cyfrowo zbiór punktów obrazu (tak zwanych pikseli) zamienić na decyzję. I to nie jest łatwe! Metodami matematycznymi służącymi do tego celu zajmowałem się od wielu lat - początkowo studiując (i tłumacząc na język polski) książki innych autorów. Potem jednak rozpocząłem w tej dziedzinie własne badania naukowe (napisałem ponad sto artykułów o wynikach tych badań) i starałem się ją spopularyzować w różnych kręgach pisząc własne książki. Były to jednak książki naukowe i chociaż są one obecnie dostępne w sieci - nie będę do nich odsyłał, bo ich studiowanie wymaga pewnego wysiłku. Zamiast tego spróbuję o tym wszystkim jasno i przystępnie odpowiedzieć, licząc na to, że uda mi się Państwa zainteresować. Zacznę od spojrzenia na całość problemu. Proces automatycznego rozpoznawania obrazu składa się z czterech etapów, przedstawionych (trochę żartobliwie...) na rysunku poniżej. Rysunek nawiązuje do tego podobszaru problematyki rozpoznawania obrazów, którym się obecnie zajmuję - to znaczy obrazowania medycznego, ale ogólny schemat jest uniwersalny i dotyczy wszelkich zastosowań rozpoznawania. Pierwszym etapem jest pozyskanie obrazu. Przy zwykłych obrazach jest to banalne - wystarczy dowolny aparat fotograficzny lub nawet zwykła komórka - i już mamy obraz cyfrowy. W przypadku obrazów medycznych, zwłaszcza dotyczących wnętrza ciała człowieka, konieczne jest użycie specjalnej aparatury, ale tym się teraz zajmować nie będziemy. Potem następuje analiza i określenie cech obrazu. To bardzo ważny etap, gdyż algorytmy opisu obrazy nie mogą (na ogół) zmagać się z milionami pikseli składającymi się na oryginalny obraz, tylko muszą dostać wygodną do interpretacji reprezentację obrazu w postaci pojedynczego punktu w przestrzeni cech. Zajmiemy się tym dokładniej za chwilę. Kolejnym etapem jest znalezienie właściwego opisu obrazu w postaci odpowiednio dobranej formuły matematycznej. Tu jest mnóstwo różnych możliwości, gdyż w toku ponad ćwierć wieku rozwoju tej problematyki wielu badaczy proponowało różne formy tego opisu i różne wynikające z nich algorytmy postępowania. O niektórych z nich napiszę dalej. No i na koniec następuje właściwe rozpoznanie obrazu i związana z nim decyzja. Wbrew pozorom jest to najłatwiejsza część zadania, bo po dobrym określeniu cech obrazu i po jego porządnym matematycznym opisaniu - podjęcie decyzji jest w istocie czynnością elementarną. Przejdźmy teraz do szczegółów. Po uzyskaniu obrazu staramy się znaleźć zestaw cech, które można automatycznie wyznaczyć na obrazie, a które na tyle dobrze charakteryzują rozpoznawane obiekty, że mając do dyspozycji same tylko cechy - można te obiekty rozpoznać. Rozpoznawanie silnie zależy od tego, jakich cech użyto do scharakteryzowania obiektu, dlatego ich wybór musi być dokładnie przemyślany. Najwygodniej jest, gdy uda się przypisać do rozpoznawanych obiektów cechy o charakterze ilościowym, to znaczy takie, które dadzą się zmierzyć, wyrazić ilościowo i odłożyć na osiach układu współrzędnych tak zwanej przestrzeni cech. Rozważmy zadanie rozpoznawania, w którym rozpoznawanymi obiektami są ludzkie twarze. Możemy każdą twarz scharakteryzować przez zmierzenie jej szerokości, wielkości ust i rozstawu oczu. Jeśli dla konkretnego obiektu (twarzy) zmierzymy te cechy i odłożymy ich wartości odpowiednio na osiach trójwymiarowego układu współrzędnych - to w przestrzeni opisywanej przez te cechy wyznaczymy pewien punkt, który może w dalszych rozważaniach reprezentować ten konkretny obiekt. Jeśli rozważymy zbiór obiektów, to każdemu obiektowi przyporządkowany będzie pewien punkt w przestrzeni cech. Położenie tego punktu będzie identyfikowało dany obiekt i pozwoli odróżnić go od innych obiektów. Strukturę rozważanej przestrzeni cech obrazuje rysunek, na którym zaznaczyłem szkice twarzy o krańcowych wartościach rozważanych cech. Przestrzeń cech (jeśli jest dobrze zbudowana) ma tę miłą właściwość, że różne obrazy twarzy tego samego człowieka będą wyznaczały punkty położone blisko siebie w tej przestrzeni, podczas gdy obrazy przedstawiające twarze innych ludzi będą położone w innym jej obszarze. Własność ta znacząco ułatwia dalsze etapy procesu rozpoznawania. W przypadku rozpoznawania twarzy, różne wizerunki twarzy tego samego człowieka powinny być rozpoznawane jako należące do jednej klasy, prowadzącej do jednej konkretnej decyzji (na przykład ). Różne obrazy twarzy tego samego człowieka obiektywnie różnią się od siebie, bo człowiek raz jest poważny, innym razem wesoły, może mieć dłuższe albo krótsze włosy, może być różnie ubrany (włączając w to nakrycie głowy), może patrzeć wprost w kamerę, albo ustawiać się profilem itd. Wszystkie te obrazy są jednak utożsamiane z tym samym rozpoznaniem () i z tą samą decyzją. Jednak w większości zastosowań rozpoznawaną klasą jest zbiór wszystkich obrazów obiektów, które mają jakieś istotne cechy wspólne, prowadzące do tej samej decyzji końcowej (takiego samego rozpoznania). Jako przykład możemy rozważyć zbiór wszystkich liter A odczytywanych ze skanowanych dokumentów. Obrazy tych liter mogą być różne, bo różne są kształty czcionki używanej do druku, różna jest ich wielkość, różny kolor, różne tło itd. - ale zawsze na podstawie takiego obrazu powinna być podjęta ta sama decyzji końcowa: . Jako inny przykład można wymienić (w zastosowaniu do diagnostyki medycznej) zbiór osób chorych na grypę. Chociaż niewątpliwie każdy pacjent ma swoje indywidualne cechy, to jednak są też cechy pozwalające na przypisanie tych wszystkich pacjentów do klasy oraz umożliwiających ich odróżnienie od osób zdrowych lub cierpiących na inne choroby. W opisanej wyżej przestrzeni cech obiekty należące do tej samej klasy tworzą skupienie dobrze odseparowane (odległe) od skupień reprezentujących obiekty innych klas. Takie grupowanie obiektów należących do jednej klasy w przestrzeni cech jest warunkiem koniecznym skutecznego rozpoznawania. Jeśli w przestrzeni cech obiekty ulegają wymieszaniu - to żadna metoda nie zapewni ich skutecznego rozpoznawania. Po określeniu cech obrazu powinien nastąpić jego opis. Przedstawiając ten etap procesu rozpoznawania jestem trochę w kłopocie, bo powinienem odwołać się do matematycznego pojęcia funkcji przynależności - a trudno jest to zrobić nie wypisując żadnych wzorów. Ale spróbuję... Funkcje przynależności pełnią podobną rolę w rozpoznawaniu obrazów, jak omawiane wcześniej funkcje przynależności w teorii zbiorów rozmytych. Jednak te funkcje przynależności, których używamy w rozpoznawaniu obrazów muszą być tworzone automatycznie przez algorytm rozpoznający na podstawie procesu uczenia. Z procesem tym spotkaliśmy się już przy omawianiu właściwości Perceptronu a także przy przedstawianiu bardzo wydajnych narzędzi sztucznej inteligencji, jakimi są sieci neuronowe. Uczenie algorytmu rozpoznającego powinno doprowadzić do tego, by w każdym punkcie przestrzeni cech dla każdej z rozpoznawanych klas obrazów można było określić, jak bardzo obiekt związany z tym właśnie punktem przestrzeni zasługuje na to, żeby można go było zaliczyć do tej właśnie klasy. Na rysunku pokazano przykładowo funkcje przynależności zbudowane dla dwóch klas w dwuwymiarowej przestrzeni cech. W rzeczywistych zadaniach rozpoznawania przestrzeń cech bywa wielowymiarowa, a rozpoznawanych klas bywa kilkadziesiąt, więc budowa funkcji przynależności nie jest zadaniem łatwym. Ale są wypracowane metody, które pozwalają to skutecznie robić nawet dla bardzo skomplikowanych zadań. Często zresztą upraszczamy zadanie i zamiast budować funkcje przynależności poszukujemy funkcji, które mogą opisywać w przestrzeni cech granice pomiędzy skupieniami poszczególnych klas. Jest to szczególnie łatwe, jeśli taka granica jest linią prostą (w przestrzeni dwuwymiarowej ) lub płaszczyzną (w przestrzeni o większej liczbie wymiarów). Nie zawsze jednak to się udaje, jak widać na rysunku po prawej stronie... Przy dobrze zbudowanym zbiorze funkcji przynależności (dla wszystkich rozpoznawanych klas!) lub przy dobrze opisanych granicach pomiędzy klasami - ostatni etap procesu rozpoznawania (rozpoznanie i decyzja) jest już łatwy. Po prostu rozpoznawany obiekt zalicza się do tej klasy, której funkcja przynależności obliczona dla tego obiektu daje największą wartość. Alternatywnie można decyzję podjąć na podstawie tego, po której stronie linii granicznej znalazł się w przestrzeni cech punkt reprezentujący rozpoznawany obiekt. Oczywiście można mnożyć wymagania, na przykład żądać tego, żeby wartość funkcji przynależności wybranej klasy dość wyraźnie dominowała nad wartościami funkcji przynależności dla "konkurencyjnych" klas itd. Ale to są już detale, nie warte szczegółowej dyskusji w tym popularnym opracowaniu. Na koniec dodam, że w prostych przypadkach rozpoznawanie można przeprowadzać także bez formalnego obliczania funkcji przynależności na podstawie prostej intuicji "". Jeśli w przestrzeni cech mamy punkty pochodzące ze zbioru uczącego (to znaczy lokalizacje obiektów, których przynależność do określonych klas jest znana) i pojawia się nowy obiekt, którego przynależność trzeba dopiero określić, to najprościej jest zaliczyć go do tej klasy, do której należą obiekty zbioru uczącego, leżące najbliżej nieznanego (rozpoznawanego) obiektu. Jest to proste i często wystarczająco skuteczne!,Ryszard TadeusiewiczZapraszam na kolejną "wyspę" w opisywanym tu archipelagu sztucznej inteligencji. Dzisiaj zajmiemy się zbiorem metod nazywanych w Polsce rozpoznawaniem obrazów, chociaż angielski odpowiednik tej nazwy "pattern recognition", czyli "rozpoznawanie wzorców" - lepiej oddaje rzeczywisty zakres rozważanych zagadnień. Badane i rozwijane są bowiem metody rozpoznawania WSZYSTKIEGO: obrazów, dźwięków (m.in. mowy), chorób (w celu wspomagania diagnostyki medycznej), sytuacji ekonomicznej (w celu optymalizacji decyzji finansowych), formacji geologicznych (w celu znajdowania nowych złóż surowców), nastrojów społecznych (w celu przewidywania wyników wyborów) itd. Warto poznać te metody! Wspomniane wyżej uogólnienia będą jednak omówione w osobnym wpisie za kilka dni, wygodnie będzie bowiem teraz przedstawić metody rozpoznawania obrazów na przykładzie ... obrazów jako takich: zdjęć, kadrów filmowych, zobrazowań medycznych, obrazów satelitarnych itp. Od tego więc zaczniemy. O zadaniu rozpoznawania obrazów jako o jednym z pierwszych problemów podejmowanych i rozwiązywanych w ramach sztucznej inteligencji była już mowa w tym blogu, gdy opisywałem Perceptron. Teraz jednak skupimy się na tym zadaniu nieco dokładniej. Zadania rozpoznawania obrazów występujące w codziennym życiu zwykle nie stanowią żadnego problemu dla człowieka. Wystarczy rzut oka - i już rozpoznajemy znajomą osobę, znany przedmiot, widywany krajobraz. Natomiast to samo zadanie dla komputera okazuje się bardzo trudne. A tymczasem potrzebujemy komputerów rozpoznających obrazy. Człowiek jest wzrokowcem i całe swoje otoczenie tak zorganizował, że najważniejsze informacje pozyskujemy za pomocą wzroku. Tak działamy w pracy, w domu i w podróży. Większość decyzji podejmujemy na podstawie tego, co widzimy! Jeśli chcemy, żeby maszyny skuteczniej pomagały nam w pracy, jeśli czekamy na robota, który będzie nas wyręczał w pracach domowych, jeśli chcemy mieć auto, które zawiezie nas bezpiecznie bez kierowcy do wymaganego miejsca - to musimy mieć komputery rozpoznające obrazy. Piszę "komputery" mając na myśli nie tylko laptopy czy komputery stacjonarne, ale także te komputery, które już są "sercem" nowoczesnych systemów produkcyjnych, które będą "mózgiem" domowego robota, czy które prędzej czy później pojawią się w samochodach. One wszystkie potrzebują umiejętności rozpoznawania obrazów. Tymczasem my ciągle nie potrafimy im tej umiejętności podarować. Na przykład, do dziś nie mamy skutecznych programów rozpoznających ludzi na podstawie ich twarzy, sylwetki, sposobu zachowania itd. Dla nas jest to dziecinnie proste. Ale komputer bardzo się z tym biedzi i często popełnia błędy. A przecież gdyby komputery umiały rozpoznawać ludzi,i to można by było zrezygnować z niewygodnych kart identyfikacyjnych, pinów, haseł , kluczy itp. Bankomat wypłacałby pieniądze na podstawie obrazu twarzy osoby, samochód otwierałby drzwi widząc nadchodzącego właściciela, wejście do mieszkania z rękami pełnymi zakupów byłoby łatwe i wygodne, bo zamiast szukać klucza wystarczyłoby pokazać do kamery buzię... Dlaczego to stale jest w sferze marzeń? Żeby odpowiedzieć na to pytanie rozważmy, jak powinien działać system rozpoznawania. Istota rozpoznawania polega na zamianie obrazu na decyzję. Początek jest łatwy, bo proces pozyskiwania cyfrowych obrazów opanowaliśmy obecnie do perfekcji - robi to każdy aparat fotograficzny, którego budowę i działanie omówiłem wcześniej. Ale potem trzeba zarejestrowany cyfrowo zbiór punktów obrazu (tak zwanych pikseli) zamienić na decyzję. I to nie jest łatwe! Metodami matematycznymi służącymi do tego celu zajmowałem się od wielu lat - początkowo studiując (i tłumacząc na język polski) książki innych autorów. Potem jednak rozpocząłem w tej dziedzinie własne badania naukowe (napisałem ponad sto artykułów o wynikach tych badań) i starałem się ją spopularyzować w różnych kręgach pisząc własne książki. Były to jednak książki naukowe i chociaż są one obecnie dostępne w sieci - nie będę do nich odsyłał, bo ich studiowanie wymaga pewnego wysiłku. Zamiast tego spróbuję o tym wszystkim jasno i przystępnie odpowiedzieć, licząc na to, że uda mi się Państwa zainteresować. Zacznę od spojrzenia na całość problemu. Proces automatycznego rozpoznawania obrazu składa się z czterech etapów, przedstawionych (trochę żartobliwie...) na rysunku poniżej. Rysunek nawiązuje do tego podobszaru problematyki rozpoznawania obrazów, którym się obecnie zajmuję - to znaczy obrazowania medycznego, ale ogólny schemat jest uniwersalny i dotyczy wszelkich zastosowań rozpoznawania. Pierwszym etapem jest pozyskanie obrazu. Przy zwykłych obrazach jest to banalne - wystarczy dowolny aparat fotograficzny lub nawet zwykła komórka - i już mamy obraz cyfrowy. W przypadku obrazów medycznych, zwłaszcza dotyczących wnętrza ciała człowieka, konieczne jest użycie specjalnej aparatury, ale tym się teraz zajmować nie będziemy. Potem następuje analiza i określenie cech obrazu. To bardzo ważny etap, gdyż algorytmy opisu obrazy nie mogą (na ogół) zmagać się z milionami pikseli składającymi się na oryginalny obraz, tylko muszą dostać wygodną do interpretacji reprezentację obrazu w postaci pojedynczego punktu w przestrzeni cech. Zajmiemy się tym dokładniej za chwilę. Kolejnym etapem jest znalezienie właściwego opisu obrazu w postaci odpowiednio dobranej formuły matematycznej. Tu jest mnóstwo różnych możliwości, gdyż w toku ponad ćwierć wieku rozwoju tej problematyki wielu badaczy proponowało różne formy tego opisu i różne wynikające z nich algorytmy postępowania. O niektórych z nich napiszę dalej. No i na koniec następuje właściwe rozpoznanie obrazu i związana z nim decyzja. Wbrew pozorom jest to najłatwiejsza część zadania, bo po dobrym określeniu cech obrazu i po jego porządnym matematycznym opisaniu - podjęcie decyzji jest w istocie czynnością elementarną. Przejdźmy teraz do szczegółów. Po uzyskaniu obrazu staramy się znaleźć zestaw cech, które można automatycznie wyznaczyć na obrazie, a które na tyle dobrze charakteryzują rozpoznawane obiekty, że mając do dyspozycji same tylko cechy - można te obiekty rozpoznać. Rozpoznawanie silnie zależy od tego, jakich cech użyto do scharakteryzowania obiektu, dlatego ich wybór musi być dokładnie przemyślany. Najwygodniej jest, gdy uda się przypisać do rozpoznawanych obiektów cechy o charakterze ilościowym, to znaczy takie, które dadzą się zmierzyć, wyrazić ilościowo i odłożyć na osiach układu współrzędnych tak zwanej przestrzeni cech. Rozważmy zadanie rozpoznawania, w którym rozpoznawanymi obiektami są ludzkie twarze. Możemy każdą twarz scharakteryzować przez zmierzenie jej szerokości, wielkości ust i rozstawu oczu. Jeśli dla konkretnego obiektu (twarzy) zmierzymy te cechy i odłożymy ich wartości odpowiednio na osiach trójwymiarowego układu współrzędnych - to w przestrzeni opisywanej przez te cechy wyznaczymy pewien punkt, który może w dalszych rozważaniach reprezentować ten konkretny obiekt. Jeśli rozważymy zbiór obiektów, to każdemu obiektowi przyporządkowany będzie pewien punkt w przestrzeni cech. Położenie tego punktu będzie identyfikowało dany obiekt i pozwoli odróżnić go od innych obiektów. Strukturę rozważanej przestrzeni cech obrazuje rysunek, na którym zaznaczyłem szkice twarzy o krańcowych wartościach rozważanych cech. Przestrzeń cech (jeśli jest dobrze zbudowana) ma tę miłą właściwość, że różne obrazy twarzy tego samego człowieka będą wyznaczały punkty położone blisko siebie w tej przestrzeni, podczas gdy obrazy przedstawiające twarze innych ludzi będą położone w innym jej obszarze. Własność ta znacząco ułatwia dalsze etapy procesu rozpoznawania. W przypadku rozpoznawania twarzy, różne wizerunki twarzy tego samego człowieka powinny być rozpoznawane jako należące do jednej klasy, prowadzącej do jednej konkretnej decyzji (na przykład ). Różne obrazy twarzy tego samego człowieka obiektywnie różnią się od siebie, bo człowiek raz jest poważny, innym razem wesoły, może mieć dłuższe albo krótsze włosy, może być różnie ubrany (włączając w to nakrycie głowy), może patrzeć wprost w kamerę, albo ustawiać się profilem itd. Wszystkie te obrazy są jednak utożsamiane z tym samym rozpoznaniem () i z tą samą decyzją. Jednak w większości zastosowań rozpoznawaną klasą jest zbiór wszystkich obrazów obiektów, które mają jakieś istotne cechy wspólne, prowadzące do tej samej decyzji końcowej (takiego samego rozpoznania). Jako przykład możemy rozważyć zbiór wszystkich liter A odczytywanych ze skanowanych dokumentów. Obrazy tych liter mogą być różne, bo różne są kształty czcionki używanej do druku, różna jest ich wielkość, różny kolor, różne tło itd. - ale zawsze na podstawie takiego obrazu powinna być podjęta ta sama decyzji końcowa: . Jako inny przykład można wymienić (w zastosowaniu do diagnostyki medycznej) zbiór osób chorych na grypę. Chociaż niewątpliwie każdy pacjent ma swoje indywidualne cechy, to jednak są też cechy pozwalające na przypisanie tych wszystkich pacjentów do klasy oraz umożliwiających ich odróżnienie od osób zdrowych lub cierpiących na inne choroby. W opisanej wyżej przestrzeni cech obiekty należące do tej samej klasy tworzą skupienie dobrze odseparowane (odległe) od skupień reprezentujących obiekty innych klas. Takie grupowanie obiektów należących do jednej klasy w przestrzeni cech jest warunkiem koniecznym skutecznego rozpoznawania. Jeśli w przestrzeni cech obiekty ulegają wymieszaniu - to żadna metoda nie zapewni ich skutecznego rozpoznawania. Po określeniu cech obrazu powinien nastąpić jego opis. Przedstawiając ten etap procesu rozpoznawania jestem trochę w kłopocie, bo powinienem odwołać się do matematycznego pojęcia funkcji przynależności - a trudno jest to zrobić nie wypisując żadnych wzorów. Ale spróbuję... Funkcje przynależności pełnią podobną rolę w rozpoznawaniu obrazów, jak omawiane wcześniej funkcje przynależności w teorii zbiorów rozmytych. Jednak te funkcje przynależności, których używamy w rozpoznawaniu obrazów muszą być tworzone automatycznie przez algorytm rozpoznający na podstawie procesu uczenia. Z procesem tym spotkaliśmy się już przy omawianiu właściwości Perceptronu a także przy przedstawianiu bardzo wydajnych narzędzi sztucznej inteligencji, jakimi są sieci neuronowe. Uczenie algorytmu rozpoznającego powinno doprowadzić do tego, by w każdym punkcie przestrzeni cech dla każdej z rozpoznawanych klas obrazów można było określić, jak bardzo obiekt związany z tym właśnie punktem przestrzeni zasługuje na to, żeby można go było zaliczyć do tej właśnie klasy. Na rysunku pokazano przykładowo funkcje przynależności zbudowane dla dwóch klas w dwuwymiarowej przestrzeni cech. W rzeczywistych zadaniach rozpoznawania przestrzeń cech bywa wielowymiarowa, a rozpoznawanych klas bywa kilkadziesiąt, więc budowa funkcji przynależności nie jest zadaniem łatwym. Ale są wypracowane metody, które pozwalają to skutecznie robić nawet dla bardzo skomplikowanych zadań. Często zresztą upraszczamy zadanie i zamiast budować funkcje przynależności poszukujemy funkcji, które mogą opisywać w przestrzeni cech granice pomiędzy skupieniami poszczególnych klas. Jest to szczególnie łatwe, jeśli taka granica jest linią prostą (w przestrzeni dwuwymiarowej ) lub płaszczyzną (w przestrzeni o większej liczbie wymiarów). Nie zawsze jednak to się udaje, jak widać na rysunku po prawej stronie... Przy dobrze zbudowanym zbiorze funkcji przynależności (dla wszystkich rozpoznawanych klas!) lub przy dobrze opisanych granicach pomiędzy klasami - ostatni etap procesu rozpoznawania (rozpoznanie i decyzja) jest już łatwy. Po prostu rozpoznawany obiekt zalicza się do tej klasy, której funkcja przynależności obliczona dla tego obiektu daje największą wartość. Alternatywnie można decyzję podjąć na podstawie tego, po której stronie linii granicznej znalazł się w przestrzeni cech punkt reprezentujący rozpoznawany obiekt. Oczywiście można mnożyć wymagania, na przykład żądać tego, żeby wartość funkcji przynależności wybranej klasy dość wyraźnie dominowała nad wartościami funkcji przynależności dla "konkurencyjnych" klas itd. Ale to są już detale, nie warte szczegółowej dyskusji w tym popularnym opracowaniu. Na koniec dodam, że w prostych przypadkach rozpoznawanie można przeprowadzać także bez formalnego obliczania funkcji przynależności na podstawie prostej intuicji "". Jeśli w przestrzeni cech mamy punkty pochodzące ze zbioru uczącego (to znaczy lokalizacje obiektów, których przynależność do określonych klas jest znana) i pojawia się nowy obiekt, którego przynależność trzeba dopiero określić, to najprościej jest zaliczyć go do tej klasy, do której należą obiekty zbioru uczącego, leżące najbliżej nieznanego (rozpoznawanego) obiektu. Jest to proste i często wystarczająco skuteczne!,Ryszard TadeusiewiczZapraszam na kolejną "wyspę" w opisywanym tu archipelagu sztucznej inteligencji. Dzisiaj zajmiemy się zbiorem metod nazywanych w Polsce rozpoznawaniem obrazów, chociaż angielski odpowiednik tej nazwy "pattern recognition", czyli "rozpoznawanie wzorców" - lepiej oddaje rzeczywisty zakres rozważanych zagadnień. Badane i rozwijane są bowiem metody rozpoznawania WSZYSTKIEGO: obrazów, dźwięków (m.in. mowy), chorób (w celu wspomagania diagnostyki medycznej), sytuacji ekonomicznej (w celu optymalizacji decyzji finansowych), formacji geologicznych (w celu znajdowania nowych złóż surowców), nastrojów społecznych (w celu przewidywania wyników wyborów) itd. Warto poznać te metody! Wspomniane wyżej uogólnienia będą jednak omówione w osobnym wpisie za kilka dni, wygodnie będzie bowiem teraz przedstawić metody rozpoznawania obrazów na przykładzie ... obrazów jako takich: zdjęć, kadrów filmowych, zobrazowań medycznych, obrazów satelitarnych itp. Od tego więc zaczniemy. O zadaniu rozpoznawania obrazów jako o jednym z pierwszych problemów podejmowanych i rozwiązywanych w ramach sztucznej inteligencji była już mowa w tym blogu, gdy opisywałem Perceptron. Teraz jednak skupimy się na tym zadaniu nieco dokładniej. Zadania rozpoznawania obrazów występujące w codziennym życiu zwykle nie stanowią żadnego problemu dla człowieka. Wystarczy rzut oka - i już rozpoznajemy znajomą osobę, znany przedmiot, widywany krajobraz. Natomiast to samo zadanie dla komputera okazuje się bardzo trudne. A tymczasem potrzebujemy komputerów rozpoznających obrazy. Człowiek jest wzrokowcem i całe swoje otoczenie tak zorganizował, że najważniejsze informacje pozyskujemy za pomocą wzroku. Tak działamy w pracy, w domu i w podróży. Większość decyzji podejmujemy na podstawie tego, co widzimy! Jeśli chcemy, żeby maszyny skuteczniej pomagały nam w pracy, jeśli czekamy na robota, który będzie nas wyręczał w pracach domowych, jeśli chcemy mieć auto, które zawiezie nas bezpiecznie bez kierowcy do wymaganego miejsca - to musimy mieć komputery rozpoznające obrazy. Piszę "komputery" mając na myśli nie tylko laptopy czy komputery stacjonarne, ale także te komputery, które już są "sercem" nowoczesnych systemów produkcyjnych, które będą "mózgiem" domowego robota, czy które prędzej czy później pojawią się w samochodach. One wszystkie potrzebują umiejętności rozpoznawania obrazów. Tymczasem my ciągle nie potrafimy im tej umiejętności podarować. Na przykład, do dziś nie mamy skutecznych programów rozpoznających ludzi na podstawie ich twarzy, sylwetki, sposobu zachowania itd. Dla nas jest to dziecinnie proste. Ale komputer bardzo się z tym biedzi i często popełnia błędy. A przecież gdyby komputery umiały rozpoznawać ludzi,i to można by było zrezygnować z niewygodnych kart identyfikacyjnych, pinów, haseł , kluczy itp. Bankomat wypłacałby pieniądze na podstawie obrazu twarzy osoby, samochód otwierałby drzwi widząc nadchodzącego właściciela, wejście do mieszkania z rękami pełnymi zakupów byłoby łatwe i wygodne, bo zamiast szukać klucza wystarczyłoby pokazać do kamery buzię... Dlaczego to stale jest w sferze marzeń? Żeby odpowiedzieć na to pytanie rozważmy, jak powinien działać system rozpoznawania. Istota rozpoznawania polega na zamianie obrazu na decyzję. Początek jest łatwy, bo proces pozyskiwania cyfrowych obrazów opanowaliśmy obecnie do perfekcji - robi to każdy aparat fotograficzny, którego budowę i działanie omówiłem wcześniej. Ale potem trzeba zarejestrowany cyfrowo zbiór punktów obrazu (tak zwanych pikseli) zamienić na decyzję. I to nie jest łatwe! Metodami matematycznymi służącymi do tego celu zajmowałem się od wielu lat - początkowo studiując (i tłumacząc na język polski) książki innych autorów. Potem jednak rozpocząłem w tej dziedzinie własne badania naukowe (napisałem ponad sto artykułów o wynikach tych badań) i starałem się ją spopularyzować w różnych kręgach pisząc własne książki. Były to jednak książki naukowe i chociaż są one obecnie dostępne w sieci - nie będę do nich odsyłał, bo ich studiowanie wymaga pewnego wysiłku. Zamiast tego spróbuję o tym wszystkim jasno i przystępnie odpowiedzieć, licząc na to, że uda mi się Państwa zainteresować. Zacznę od spojrzenia na całość problemu. Proces automatycznego rozpoznawania obrazu składa się z czterech etapów, przedstawionych (trochę żartobliwie...) na rysunku poniżej. Rysunek nawiązuje do tego podobszaru problematyki rozpoznawania obrazów, którym się obecnie zajmuję - to znaczy obrazowania medycznego, ale ogólny schemat jest uniwersalny i dotyczy wszelkich zastosowań rozpoznawania. Pierwszym etapem jest pozyskanie obrazu. Przy zwykłych obrazach jest to banalne - wystarczy dowolny aparat fotograficzny lub nawet zwykła komórka - i już mamy obraz cyfrowy. W przypadku obrazów medycznych, zwłaszcza dotyczących wnętrza ciała człowieka, konieczne jest użycie specjalnej aparatury, ale tym się teraz zajmować nie będziemy. Potem następuje analiza i określenie cech obrazu. To bardzo ważny etap, gdyż algorytmy opisu obrazy nie mogą (na ogół) zmagać się z milionami pikseli składającymi się na oryginalny obraz, tylko muszą dostać wygodną do interpretacji reprezentację obrazu w postaci pojedynczego punktu w przestrzeni cech. Zajmiemy się tym dokładniej za chwilę. Kolejnym etapem jest znalezienie właściwego opisu obrazu w postaci odpowiednio dobranej formuły matematycznej. Tu jest mnóstwo różnych możliwości, gdyż w toku ponad ćwierć wieku rozwoju tej problematyki wielu badaczy proponowało różne formy tego opisu i różne wynikające z nich algorytmy postępowania. O niektórych z nich napiszę dalej. No i na koniec następuje właściwe rozpoznanie obrazu i związana z nim decyzja. Wbrew pozorom jest to najłatwiejsza część zadania, bo po dobrym określeniu cech obrazu i po jego porządnym matematycznym opisaniu - podjęcie decyzji jest w istocie czynnością elementarną. Przejdźmy teraz do szczegółów. Po uzyskaniu obrazu staramy się znaleźć zestaw cech, które można automatycznie wyznaczyć na obrazie, a które na tyle dobrze charakteryzują rozpoznawane obiekty, że mając do dyspozycji same tylko cechy - można te obiekty rozpoznać. Rozpoznawanie silnie zależy od tego, jakich cech użyto do scharakteryzowania obiektu, dlatego ich wybór musi być dokładnie przemyślany. Najwygodniej jest, gdy uda się przypisać do rozpoznawanych obiektów cechy o charakterze ilościowym, to znaczy takie, które dadzą się zmierzyć, wyrazić ilościowo i odłożyć na osiach układu współrzędnych tak zwanej przestrzeni cech. Rozważmy zadanie rozpoznawania, w którym rozpoznawanymi obiektami są ludzkie twarze. Możemy każdą twarz scharakteryzować przez zmierzenie jej szerokości, wielkości ust i rozstawu oczu. Jeśli dla konkretnego obiektu (twarzy) zmierzymy te cechy i odłożymy ich wartości odpowiednio na osiach trójwymiarowego układu współrzędnych - to w przestrzeni opisywanej przez te cechy wyznaczymy pewien punkt, który może w dalszych rozważaniach reprezentować ten konkretny obiekt. Jeśli rozważymy zbiór obiektów, to każdemu obiektowi przyporządkowany będzie pewien punkt w przestrzeni cech. Położenie tego punktu będzie identyfikowało dany obiekt i pozwoli odróżnić go od innych obiektów. Strukturę rozważanej przestrzeni cech obrazuje rysunek, na którym zaznaczyłem szkice twarzy o krańcowych wartościach rozważanych cech. Przestrzeń cech (jeśli jest dobrze zbudowana) ma tę miłą właściwość, że różne obrazy twarzy tego samego człowieka będą wyznaczały punkty położone blisko siebie w tej przestrzeni, podczas gdy obrazy przedstawiające twarze innych ludzi będą położone w innym jej obszarze. Własność ta znacząco ułatwia dalsze etapy procesu rozpoznawania. W przypadku rozpoznawania twarzy, różne wizerunki twarzy tego samego człowieka powinny być rozpoznawane jako należące do jednej klasy, prowadzącej do jednej konkretnej decyzji (na przykład ). Różne obrazy twarzy tego samego człowieka obiektywnie różnią się od siebie, bo człowiek raz jest poważny, innym razem wesoły, może mieć dłuższe albo krótsze włosy, może być różnie ubrany (włączając w to nakrycie głowy), może patrzeć wprost w kamerę, albo ustawiać się profilem itd. Wszystkie te obrazy są jednak utożsamiane z tym samym rozpoznaniem () i z tą samą decyzją. Jednak w większości zastosowań rozpoznawaną klasą jest zbiór wszystkich obrazów obiektów, które mają jakieś istotne cechy wspólne, prowadzące do tej samej decyzji końcowej (takiego samego rozpoznania). Jako przykład możemy rozważyć zbiór wszystkich liter A odczytywanych ze skanowanych dokumentów. Obrazy tych liter mogą być różne, bo różne są kształty czcionki używanej do druku, różna jest ich wielkość, różny kolor, różne tło itd. - ale zawsze na podstawie takiego obrazu powinna być podjęta ta sama decyzji końcowa: . Jako inny przykład można wymienić (w zastosowaniu do diagnostyki medycznej) zbiór osób chorych na grypę. Chociaż niewątpliwie każdy pacjent ma swoje indywidualne cechy, to jednak są też cechy pozwalające na przypisanie tych wszystkich pacjentów do klasy oraz umożliwiających ich odróżnienie od osób zdrowych lub cierpiących na inne choroby. W opisanej wyżej przestrzeni cech obiekty należące do tej samej klasy tworzą skupienie dobrze odseparowane (odległe) od skupień reprezentujących obiekty innych klas. Takie grupowanie obiektów należących do jednej klasy w przestrzeni cech jest warunkiem koniecznym skutecznego rozpoznawania. Jeśli w przestrzeni cech obiekty ulegają wymieszaniu - to żadna metoda nie zapewni ich skutecznego rozpoznawania. Po określeniu cech obrazu powinien nastąpić jego opis. Przedstawiając ten etap procesu rozpoznawania jestem trochę w kłopocie, bo powinienem odwołać się do matematycznego pojęcia funkcji przynależności - a trudno jest to zrobić nie wypisując żadnych wzorów. Ale spróbuję... Funkcje przynależności pełnią podobną rolę w rozpoznawaniu obrazów, jak omawiane wcześniej funkcje przynależności w teorii zbiorów rozmytych. Jednak te funkcje przynależności, których używamy w rozpoznawaniu obrazów muszą być tworzone automatycznie przez algorytm rozpoznający na podstawie procesu uczenia. Z procesem tym spotkaliśmy się już przy omawianiu właściwości Perceptronu a także przy przedstawianiu bardzo wydajnych narzędzi sztucznej inteligencji, jakimi są sieci neuronowe. Uczenie algorytmu rozpoznającego powinno doprowadzić do tego, by w każdym punkcie przestrzeni cech dla każdej z rozpoznawanych klas obrazów można było określić, jak bardzo obiekt związany z tym właśnie punktem przestrzeni zasługuje na to, żeby można go było zaliczyć do tej właśnie klasy. Na rysunku pokazano przykładowo funkcje przynależności zbudowane dla dwóch klas w dwuwymiarowej przestrzeni cech. W rzeczywistych zadaniach rozpoznawania przestrzeń cech bywa wielowymiarowa, a rozpoznawanych klas bywa kilkadziesiąt, więc budowa funkcji przynależności nie jest zadaniem łatwym. Ale są wypracowane metody, które pozwalają to skutecznie robić nawet dla bardzo skomplikowanych zadań. Często zresztą upraszczamy zadanie i zamiast budować funkcje przynależności poszukujemy funkcji, które mogą opisywać w przestrzeni cech granice pomiędzy skupieniami poszczególnych klas. Jest to szczególnie łatwe, jeśli taka granica jest linią prostą (w przestrzeni dwuwymiarowej ) lub płaszczyzną (w przestrzeni o większej liczbie wymiarów). Nie zawsze jednak to się udaje, jak widać na rysunku po prawej stronie... Przy dobrze zbudowanym zbiorze funkcji przynależności (dla wszystkich rozpoznawanych klas!) lub przy dobrze opisanych granicach pomiędzy klasami - ostatni etap procesu rozpoznawania (rozpoznanie i decyzja) jest już łatwy. Po prostu rozpoznawany obiekt zalicza się do tej klasy, której funkcja przynależności obliczona dla tego obiektu daje największą wartość. Alternatywnie można decyzję podjąć na podstawie tego, po której stronie linii granicznej znalazł się w przestrzeni cech punkt reprezentujący rozpoznawany obiekt. Oczywiście można mnożyć wymagania, na przykład żądać tego, żeby wartość funkcji przynależności wybranej klasy dość wyraźnie dominowała nad wartościami funkcji przynależności dla "konkurencyjnych" klas itd. Ale to są już detale, nie warte szczegółowej dyskusji w tym popularnym opracowaniu. Na koniec dodam, że w prostych przypadkach rozpoznawanie można przeprowadzać także bez formalnego obliczania funkcji przynależności na podstawie prostej intuicji "". Jeśli w przestrzeni cech mamy punkty pochodzące ze zbioru uczącego (to znaczy lokalizacje obiektów, których przynależność do określonych klas jest znana) i pojawia się nowy obiekt, którego przynależność trzeba dopiero określić, to najprościej jest zaliczyć go do tej klasy, do której należą obiekty zbioru uczącego, leżące najbliżej nieznanego (rozpoznawanego) obiektu. Jest to proste i często wystarczająco skuteczne!,Ryszard Tadeusiewicz